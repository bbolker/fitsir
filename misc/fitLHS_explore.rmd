---
title: "Exploring fitLHS results"
output: html_document
---

```{r pkgs,echo=FALSE,message=FALSE}
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2); theme_set(theme_bw())
```
```{r load, echo = FALSE}
fn <- "fitLHS.rda"
fn2 <- "fitLHS2.rda"
## BMB: what's the difference?
## SWP: L2 uses L1 as starting values to fit the curve
L1 <- load(fn)
L2 <- load(fn2)
```

I performed 500 simulations based on these parameters:

```{r pars}
colnames(p) <- c("log.beta", "log.gamma", "log.N", "logit.i")
pairs(~log.beta+log.gamma+log.N+logit.i, data = as.data.frame(p),
      gap=0,cex=0.5)
```

Does `fitsir.optim` perform better than `fitsir`? I put the parameters in an increasing order to see if we get a stair-like shape:

```{r plotranks,echo=FALSE, warning=FALSE}
dd <- rbind(data.frame(method="fitsir",NLL1=f.nll,NLL2=f.nll2),
      data.frame(method="fitsir.optim",NLL1=s.nll,NLL2=s.nll2)) %>%
    gather(run,NLL,-method) %>%
    group_by(method,run) %>%
    mutate(r=rank(NLL))
ggplot(dd,aes(r,NLL,colour=method,linetype=run))+geom_line()+
    labs(x="rank",y="negative log-likelihood")+
    scale_colour_brewer(palette="Set1")
```

How many NA values?

```{r,natab}
with(dd,table(is.na(NLL),run,method))
```

```{r performe1,echo = FALSE}
par(mfrow = c(1,2))
ylim <- c(-30, 30)
matplot(apply(fpars, 2, sort), type = "l", ylab = "param value", main = "fitsir", ylim = ylim)
text(8,tail(fpars,1),colnames(fpars),col=1:4,adj=-1)
matplot(apply(spars, 2, sort), type = "l", ylab = "param value", main = "fitsir.optim", ylim = ylim)
text(8,tail(fpars,1),colnames(fpars),col=1:4,adj=-1)
```

Let's try Raue et al graph:

```{r raue}
tmpfun <- function(n.sample, i1, i2){
    set.seed(101)
    na.vec <- which(is.na(fpars[,1]))
    sim <- c(1:500)
    s.n <- sample(sim[-na.vec], n.sample)
    p.sample <- p[s.n,]
    fpars.sample <- fpars[s.n,]
    plot(p.sample[,c(i1,i2)], xlim = c(-2, 8), ylim = c(-2, 6))
    points(fpars.sample[,c(i1,i2)], col = 2)
    arrows(p.sample[,i1], p.sample[,i2], x1=fpars.sample[,i1], y1 = fpars.sample[,i2], col = "Gray")
}

par(mfrow = c(1,1))
tmpfun(50, 1, 2) 
```

I'm going to sort out the good fits:

```{r goodfits}
fpars.good <- fpars[(f.nll < 169),]
f.nll.good <- f.nll[(f.nll < 169)]
```

This is quite interesting...

```{r}
pairs(~log.beta+log.gamma+log.N+logit.i, data = as.data.frame(fpars.good),
      gap=0,cex=0.5)
```

Let's try plotting all of them:

```{r good.fits2, error = FALSE, message=FALSE}
library(fitsir)
par(mfrow = c(1,1))
hist(f.nll.good)

bombay2 <- setNames(bombay, c("tvec", "count"))
tmpfun2 <- function(i, pars){
    I <- SIR.detsim(bombay2$tvec, trans.pars(pars[i,]))
}
library(reshape2)
tmpfun3 <- function(n, pars){
    good.sims <- list()
    good.sims <- lapply(c(1:n),function(i){data.frame(tvec = bombay2$tvec, count = tmpfun2(i, pars))})
    mL <- melt(good.sims, id.vars = "tvec")
ggplot(bombay2, aes(tvec, count)) + geom_point() +
    geom_line(data = mL, aes(tvec, value, group = L1), col = "Gray")
}

n <- nrow(fpars.good)
tmpfun3(n, fpars.good)
```

Reparameterization:

```{r reparm, warning = FALSE}

fpars.good <- transform(fpars.good,
          log.R0 = log(exp(log.beta)/exp(log.gamma)),
          log.r = log(exp(log.beta)-exp(log.gamma)),
          log.S0 = log(exp(log.N) * (1 - plogis(logit.i))),
          log.I0 = log(exp(log.N) * plogis(logit.i)))

library(GGally)
ggpairs(fpars.good[,-(1:4)])

fpars.good2 <- fpars.good[(f.nll.good < 167.7),]
f.nll.good2 <- f.nll.good[(f.nll.good < 167.7)]

hist(f.nll.good2)

ggpairs(fpars.good2[,-(1:4)])

```
