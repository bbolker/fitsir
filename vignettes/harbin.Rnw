%\VignetteEngine{knitr::knitr}
%\VignetteDepends{ggplot2}
%\VignetteDepends{plyr}
%\VignetteDepends{reshape2}
%\VignetteIndexEntry{Simple SIR model fitting}
\documentclass{article}
\title{Basic SIR fitting}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage{hyperref}
\newcommand{\rzero}{{\cal R}_0}
\newcommand{\code}[1]{{\tt #1}}
\bibliographystyle{chicago}
\date{\today}
\begin{document}
\maketitle

<<opts,echo=FALSE>>=
library("knitr")
opts_chunk$set(fig.width=5,fig.height=5,tidy=FALSE,message=FALSE,error=FALSE,warning=FALSE)
@

\section{Harbin}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=4in]{Dietz_harbin_sm.png}
\end{center}
\caption{Unnumbered figure (p. 102) from \cite{dietz_epidemics:_2009} showing the Harbin epidemic.}
\label{fig:dietzfig}
\end{figure}

Figure~\ref{fig:dietzfig} shows a Kermack-Mckendrick model fit to Harbin plague data. Based on the equations  (\ref{eq:km}) and estimates (``$x_0 = 2985$, $\rzero=2.00$ and
a mean infectious period of 11 days'') that \cite{dietz_epidemics:_2009} provides, we can compare how Kermack-Mckendrick model fit differs from SIR model fit based on maximum likelihood estimation.
\begin{equation}
\begin{split}
\frac{dz}{dt} & = \frac{\gamma x_0}{2 \rzero^2} c_1 \text{sech}^2(c_1 \gamma t - c_2) , \\
c_1 & = \sqrt{(\rzero-1)^2 + \frac{2 \rzero^2}{x_0}} \\
c_2 & = \text{tanh}^{-1} \left(\frac{\rzero-1}{c_1}\right).
\label{eq:km}
\end{split}
\end{equation}
We note that the original equation provided by \cite{dietz_epidemics:_2009} contains a typo. $c_1 \gamma t$ after $\text{sech}^2$ in the first equation should be corrected to $c_1 \gamma t/2$ \citep{kermack1927contribution}.

First, load the pacakge: 
<<load>>==
library(fitsir)
@

\noindent 
Since \code{fitsir} package lazy loads all data, \code{data(harbin)} is unnecessary.
<<harbin_head>>==
head(harbin)
@

Then, we transform the parameters provided by \cite{dietz_epidemics:_2009} into \emph{unconstrained parameters} (\code{log.beta, log.gamma, log.N, logit.i}) so that they can be used as starting parameters for MLE. Although \code{fitsir} expects a dataframe with column names \code{times} and \code{count}, we can specify a time column and a count column with \code{tcol} and \code{icol} arguments.

<<harbin_fit>>==
dietz_harbin <- c(x0=2985,rzero=2,gamma=7/11)
dietz_lpars <- with(as.list(dietz_harbin),
      c(log.beta=log(rzero*gamma),
        log.gamma=log(gamma),
        log.N=log(x0),
        logit.i=qlogis(1e-3)))
(ff <- fitsir(harbin, start=dietz_lpars, type="death", 
              tcol="week", icol="Deaths", method="BFGS"))
@

\noindent 
In this case, BFGS method has been used because using sensitivity equations allows for more accurate computation of the Hessian matrix. 

We can plot \code{fitsir} objects using \code{plot} function to see whether this fit is good or not (\code{plot(ff)}). Here, we plot SIR fit along with Dietz fit to compare how they differ:
<<harbin_plot, echo = TRUE, message = FALSE, fig.height=4>>=
plot(ff, main="SIR vs. KM comparison")
times <- with(as.list(harbin), seq(min(week), max(week), by = 0.1))
dpKM <- with(as.list(dietz_harbin), 
        {
           c1 <- sqrt((rzero-1)^2+2*rzero^2/x0)
           c2 <- atanh((rzero-1)/c1)
           gamma*x0/(2*rzero^2)*c1*
               (1/cosh(c1*gamma*times/2-c2))^2
        })
lines(times,dpKM, col = 2)
legend(x=2, y=275, legend=c("SIR","Dietz"), col=c("black", "red"), lty = 1)
@

\noindent
Apart from the differences in the estimated trajectories, we note that the Kermack-Mckendrick equation models the instantaneous change in the number of recovered individuals ($dR/dt$) whereas \code{fitsir} fits are based on the actual number of individuals that recovered during a given time interval ($R(\tau_{n+1}) - R(\tau_n)$).

We can also use the \code{summary} method provided by the \code{fitsir} package to see the summarized parameters:
<<harbin_summary>>=
summary(ff)
@

\noindent
MLE returns slightly higher $\rzero$ and longer infectious period but lower population size.

In fact, this is not the best fit. By looking at the Pearson residual, we can see that the data is over dispersed

<<harbin_test>>==
pp <- predict(ff)
(pr <- sum((harbin$Deaths-pp$mean)^2/pp$mean)/(nrow(harbin)-1))
@

\noindent
\code{fitsir} provides three ways of dealing with overdispersion (quasipossion, NB1, NB2) and in this case, using NB1 error function fits better (higher Log-likelihood) than using any of the provided error functions. First, to explore how these fits differ, we define a new data frame, namely \code{harbin2}, to avoid using \code{tcol} and \code{icol} arguments:

<<harbin2>>==
harbin2 <- setNames(harbin, c("times", "count"))
@

\noindent
Then, we can fit:

<<harbin_dispersion>>=
ff2 <- fitsir(harbin2, dist="quasipoisson", type="death", method="BFGS")
ff3 <- fitsir(harbin2, dist="nbinom", type="death")
ff4 <- fitsir(harbin2, dist="nbinom1", type="death", hessian.opts=list(r=6))
@

\noindent
For \code{nbinom1}, \code{hessian.opts=list(r=6)} was used because default Hessian calculation is not stable.

Again, we can plot these three fits to compare:

<<harbin_dispersion_plot, fig.width=8>>==
plot(ff2, level=0.95, col.traj="green", col.conf="green", log="y", main="Comparison of three error functions")
plot(ff3, level=0.95, add=TRUE, col.traj="blue", col.conf="blue")
plot(ff4, level=0.95, add=TRUE, col.traj="red", col.conf="red")
legend(x=2, y=275, legend=c("Qausipoisson","NB2", "NB1"), col=c("green", "blue", "red"), lty = 1)
@

All these three fits give us very similar expected trajectories as well as confidence intervals. However, if we compare their log-likelihoods, we find that NB1 gives us the best fit.

<<harbin_logLik>>==
hfits <- list(QP=ff2, NB2=ff3, NB1=ff4)
lapply(hfits, logLik)
@

To understand why NB1 fits better than NB2, we can look at the mean variance relationship (we disregard quasipoisson).  

<<mean-variance, echo=FALSE>>==
library(dplyr)
library(ggplot2); theme_set(theme_bw())
mvrel <- function(fit, data) {
    mean <- SIR.detsim(data$times, coef(fit, "trans"), type="death")
    data.frame(
        mean=mean,
        var=(data$count-mean)^2
    )
}
level <- seq(0, 300, by = 25)

mvfun <- . %>%
    mvrel(harbin2) %>%
    mutate(group=cut(mean, breaks=level)) %>%
    group_by(group) %>%
    summarise(mean2 = mean(mean), var2=mean(var), n=length(var))

mvtot <- hfits %>%
    lapply(mvfun) %>%
    bind_rows(.id="dist") %>%
    filter(dist != "QP")

nb1k <- fitsir:::mledsp(harbin2$count, predict(ff4)$mean, "nbinom1")
nb2k <- fitsir:::mledsp(harbin2$count, predict(ff3)$mean, "nbinom")

ggplot(mvtot, aes(mean2, var2)) + 
    geom_point(aes(size=n, col=dist), pch=1) +
    scale_x_continuous(lim=c(0, 250), expand = c(0,0), name="mean") +
    scale_y_continuous(lim=c(0, 600), expand = c(0, 0), name="variance") +
    scale_size_continuous(range = c(5, 20), guide=FALSE) +
    geom_abline(intercept=0,slope=nb1k) + 
    stat_function(fun=function(x) x + x^2/nb2k, linetype=2)
@

\bibliography{plague}
\end{document}
